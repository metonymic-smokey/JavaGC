# Object Analyzer

A pipeline to extract and analyze object lifetimes from a Java program.

More details can be found in the paper titled "Analysis of Garbage Collection Patterns to Extend Microbenchmarks for Big Data Workloads" (TODO: add link once published).

## Usage

### Requirements

- Docker (tested on v20.10)
- bash (tested on v5.0)

### Running on a JAR file

If you have a JAR file that you want to analyze, use the `run.sh` script as:
```bash
./run.sh <absolute path to JAR file> [<args to JAR file>...]
```

The outputs will be saved to a subdirectory in `./outputs/` - look for the last line in the script's output to get the full path.

The output directory contains:
- `output/data___lifetimes_._parquet` subdirectory contains graphs generated by the analysis.
- `data` subdirectory contains raw object level data as a CSV (this can be quite large - please delete it if not required) and as a Parquet file.
- `trace_files` subdirectory contains trace, symbols and class definitions file generated by the modified AntTracks JVM.

### Running on generated trace files

If you have generated a trace file (with symbols and class definitions files too) using the AntTracks JVM separately, you can use the `on_traces.sh` script as:
```
./on_traces.sh <absolute path to trace file>
```

Note: the directory containing the trace file must also contain the symbols and class definitions files with the same suffix.

The outputs will be saved to a subdirectory in `./outputs/` - look for the last line in the script's output to get the full path.


The output directory structure is similar to [Running on a JAR file](#running-on-a-jar-file) except that `trace_files` subdirectory is not generated.

## Directory structure

TODO.

## License

GPLv2
